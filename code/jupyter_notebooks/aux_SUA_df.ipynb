{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1ed4c08-2089-4e41-b8bf-01fda9e50b01",
   "metadata": {},
   "source": [
    "# Auxiliary notebook for a SUA properties calculation script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bea475c-3c6c-4c72-a4ee-df426988b615",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b363c3d9-a470-4868-b4ac-73003d9ac547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('/CSNG/studekat/ripple_band_project/code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4524dc0d-cb81-471d-8400-fb13ebea12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_analysis import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pickle\n",
    "import neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81388d2-3c1e-4411-b216-55216dad7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f144a260-7100-48fd-b642-8271a5fd58f3",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05d0790-3dc0-460f-bb79-ebd5a2d03adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/CSNG/studekat/ripple_band_project/code/params_analysis.yml\") as f:\n",
    "    params = yaml.safe_load(f)\n",
    "### AUX = params['aux']\n",
    "\n",
    "DATA_FOLDER = params['data_folder'] ### folder with all the preprocessed data\n",
    "DATES = params['dates']\n",
    "#PEAK_BORDERS = params['phase_peak_borders']\n",
    "WIDTH_INTERVALS = params['width_intervals'] #[(0,7),(8,12),(13,90)]\n",
    "FINAL_CLASSES = ['DOWN_narrow_peak','DOWN_narrow_other','DOWN_medium','DOWN_wide','UP_peak','UP_other']\n",
    "\n",
    "DF_FOLDER = '/CSNG/studekat/ripple_band_project/dataframes' ### here the resulting dataframes will be saved\n",
    "MONKEY_LIST = ['L','N','F','A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2547a4cf-3862-45ce-91b4-5f18bbfa7029",
   "metadata": {},
   "source": [
    "## Data handling sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf89703d-fd01-4789-91d3-8c075dbe1092",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = load_block('N',1,type_rec='RS',type_sig='spikes',date=DATES['N']['RS'][0],data_folder=DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc4568bc-708a-4d70-8e60-b8d416c191f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(block.segments[0].spiketrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08869d9d-e2d4-4064-8b28-ec6e92255b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey = 'L'\n",
    "array = 1\n",
    "date = '20180806'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2333fad5-046c-4639-a9f6-267387f4e0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start t RB: 3\n",
      "Start t spikes: 0\n",
      "Spikes and ripples do not have the same start time.\n"
     ]
    }
   ],
   "source": [
    "spike_block = load_block(monkey,array,type_rec='OG',type_sig='spikes',date=date,data_folder=DATA_FOLDER) ### SUA\n",
    "RB_block = load_block(monkey,array,type_rec='OG',type_sig='RB',date=date,data_folder=DATA_FOLDER)\n",
    "num_cells = len(spike_block.segments[0].spiketrains)\n",
    "start_t_spikes_ms = int(np.floor(np.float64(spike_block.segments[0].spiketrains[0].t_start.magnitude)*1000))\n",
    "start_t_RB_ms = int(np.floor(np.float64(RB_block.segments[0].analogsignals[0].t_start.magnitude)*1000))\n",
    "print(f'Start t RB: {start_t_RB_ms}')\n",
    "print(f'Start t spikes: {start_t_spikes_ms}')\n",
    "if start_t_spikes_ms!=start_t_RB_ms:\n",
    "    print('Spikes and ripples do not have the same start time.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96838b1-e03a-4b6c-9a03-14fb5d2311e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RB_block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc0c15-acae-4915-a233-c732208fcf46",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf5ea65-cf54-498e-b5fe-1ee3cfe8c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_train_prop_vec(spike_vector,rb_phase,rb_envelope,rb_env_phase,channel_prop=None,indicator=None,indicator_name='EC'):\n",
    "    \"\"\"\n",
    "    THIS IS NOT THE LATEST VERSION.\n",
    "\n",
    "    \n",
    "    TODO better description\n",
    "    \n",
    "    Calculates properties of one spiketrain.\n",
    "\n",
    "    spike_train is a spike train directly from the nix file, with all metadata included\n",
    "    \"\"\"\n",
    "    from copy import deepcopy \n",
    "\n",
    "    if indicator is not None:\n",
    "        mask = indicator>0\n",
    "        spike_vector = spike_vector[mask]\n",
    "        rb_phase = rb_phase[mask]\n",
    "        rb_envelope = rb_envelope[mask]\n",
    "        rb_env_phase = rb_env_phase[mask]\n",
    "        \n",
    "    ### lists of RB phases and envs. of spikes - CAREFUL WITH MULTIPLE SPIKES IN ONE MS\n",
    "    phases_list = []\n",
    "    env_list = []\n",
    "    phases_env_list = []\n",
    "    aux_sp = deepcopy(spike_vector)\n",
    "    while np.sum(aux_sp)>0:\n",
    "        non_zero_idx = np.where(aux_sp>0)[0]\n",
    "        for idx in non_zero_idx:\n",
    "            phases_list.append(rb_phase[idx]) \n",
    "            env_list.append(rb_envelope[idx]) \n",
    "            phases_env_list.append(rb_env_phase[idx]) \n",
    "            aux_sp[idx]-=1 ### subtracting spikes that we have already used\n",
    "\n",
    "    ### phase preference\n",
    "    r, phi = circular_avg(np.array(phases_list),bins=30)\n",
    "    r_env, phi_env = circular_avg(np.array(phases_env_list),bins=30)\n",
    "\n",
    "    ### phases of high and low envelope spikes \n",
    "    high_env_mask = np.array(env_list)>=np.median(rb_envelope) #### mask from the envelope values for each spike (NOT IN SHAPE OF INPUT ARRAYS, only spikes)\n",
    "    low_env_mask = np.array(env_list)<np.median(rb_envelope)\n",
    "    \n",
    "    list_phases_high_env = np.array(phases_list)[high_env_mask]\n",
    "    list_phases_low_env = np.array(phases_list)[low_env_mask]\n",
    "\n",
    "    list_env_phases_high_env = np.array(phases_env_list)[high_env_mask]\n",
    "    list_env_phases_low_env = np.array(phases_env_list)[low_env_mask]\n",
    "\n",
    "    ### firing rate \n",
    "    dur_rec_ms = spike_vector.shape[0]\n",
    "    dur_rec_s = dur_rec_ms/1000\n",
    "    fr = np.sum(spike_vector)/dur_rec_s\n",
    "    fr_high_env = len(list_phases_high_env)/dur_rec_s*2 ### we normalise by 2, because this only considers spikes above median env.\n",
    "    fr_low_env = len(list_phases_low_env)/dur_rec_s*2\n",
    "    \n",
    "    ### CV ISI\n",
    "    len_intervals = count_zero_intervals(spike_vector) \n",
    "    CV_ISI = np.std(np.array(len_intervals))/np.mean(np.array(len_intervals))\n",
    "\n",
    "    if indicator is None:\n",
    "        ind_string = ''\n",
    "    else:\n",
    "        if indicator_name is not None:\n",
    "            ind_string = f'_{indicator_name}'\n",
    "        else:\n",
    "            print('No indicator name given.')\n",
    "            return\n",
    "        \n",
    "    prop_dict = {f'FR{ind_string}':fr, \n",
    "                f'CV_ISI{ind_string}': CV_ISI,\n",
    "                f'ISI{ind_string}': len_intervals,\n",
    "\n",
    "                f'env_th_median{ind_string}':np.median(rb_envelope), ### the median value of RB envelope on this channel\n",
    "                 \n",
    "                f'list_phases{ind_string}': phases_list,\n",
    "                f'list_env{ind_string}':env_list,\n",
    "                f'list_env_phases{ind_string}':phases_env_list,\n",
    "\n",
    "                f'list_phases_high_env{ind_string}':list_phases_high_env,\n",
    "                f'list_env_phases_high_env{ind_string}':list_env_phases_high_env,\n",
    "                 \n",
    "                f'list_phases_low_env{ind_string}':list_phases_low_env,\n",
    "                f'list_env_phases_low_env{ind_string}':list_env_phases_low_env,\n",
    "\n",
    "                f'FR_high_env_median{ind_string}':fr_high_env,\n",
    "                f'FR_low_env_median{ind_string}':fr_low_env, \n",
    "                f'FR_high_env_low_env_median_ratio{ind_string}':fr_high_env/fr_low_env, \n",
    "                 \n",
    "                f'pref_phase_spikes{ind_string}':phi, \n",
    "                f'norm_RB_phase_selectivity_spikes{ind_string}':r, \n",
    "                f'pref_env_phase_spikes{ind_string}': phi_env,\n",
    "                f'norm_RB_env_phase_selectivity_spikes{ind_string}': r_env,\n",
    "                }\n",
    "    # adding other percentile TH values, so the spikes can be splitted into high/low env. in different ways later\n",
    "    for perc in [10,20,30,40,50,60,70,80,90,95]:\n",
    "        prop_dict[f'env_th_perc_{perc}{ind_string}'] = np.percentile(rb_envelope,perc)\n",
    "    \n",
    "    if channel_prop is not None:\n",
    "        for k in channel_prop.keys():\n",
    "            prop_dict[k] = channel_prop[k]\n",
    "    return prop_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d5eaca-685a-4036-9685-235fdbc0627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aux_add_up_down_classes(df_sua):\n",
    "    \"\"\"\n",
    "    Clasifies whether the peak is UP or DOWN (bigger in abs. val above, or below 0), in the zscored waveform.\n",
    "    \"\"\"\n",
    "    df_added = df_sua\n",
    "    aux_classes = []\n",
    "    for idx in df_added.index:\n",
    "        wf = df_added.loc[idx]['avg_wf']\n",
    "        if np.abs(np.max(wf))>np.abs(np.min(wf)):\n",
    "            aux_classes.append('UP')\n",
    "        else:\n",
    "            aux_classes.append('DOWN')\n",
    "\n",
    "    df_added['wf_direction'] = aux_classes\n",
    "    return df_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e860b998-735c-4e4a-906f-c8f35cbc9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aux_add_waveform_prop(df_sua):\n",
    "    \"\"\"\n",
    "    From the dataframe with formated waveform properties calculates waveform width and height (amplitude).\n",
    "    \"\"\"\n",
    "    df_added = df_sua\n",
    "    ### amplitude\n",
    "    waveforms = df_sua['avg_wf'].values\n",
    "    df_added['amp_wf'] = [np.max(wf) - np.min(wf) for wf in waveforms]\n",
    "    ### distance from peak to trough\n",
    "    min_idcs = [np.argmin(wf) for wf in waveforms]\n",
    "    df_added['width_wf'] = [np.abs(np.argmax(wf[min_idx:])+min_idx - np.argmin(wf)) for wf, min_idx in zip(waveforms,min_idcs)]\n",
    "    return df_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "301ae774-b7f1-4c22-aaef-81cd1a22f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aux_add_zscored_avg_waveform(df_sua):\n",
    "    \"\"\"\n",
    "    From a dataframe with formated waveforms, saves one more column with each waveform zscored, \n",
    "    and another column with its zscored amplitude.\n",
    "    \"\"\"\n",
    "    from scipy.stats import zscore\n",
    "    \n",
    "    waveforms = df_sua['avg_wf'].values\n",
    "    df_added = df_sua\n",
    "    df_added['avg_wf_zscored'] =  [zscore(wf.magnitude) for wf in waveforms]\n",
    "    wfs_zsc = df_added['avg_wf_zscored'].values\n",
    "    df_added['amp_wf_zscored'] = [np.max(wf) - np.min(wf) for wf in wfs_zsc]\n",
    "    \n",
    "    return df_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d0248de-06d3-43f4-8b4c-f5770e5e121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aux_add_width_classes(df_sua,width_intervals = WIDTH_INTERVALS):\n",
    "    \"\"\"\n",
    "    Adding width class info, based on the measured width of a waveform (peak to the right max.).\n",
    "    \"\"\"\n",
    "    names_widths = ['narrow','medium','wide']\n",
    "    df_added = df_sua\n",
    "    ### adding column with spike width classification into narrow, medium, wide\n",
    "    aux_classes = []\n",
    "    for idx in df_added.index:\n",
    "        width_row = df_added.loc[idx]['width_wf']\n",
    "        for i in range(len(width_intervals)):\n",
    "            interval = width_intervals[i]\n",
    "            if (width_row>=interval[0]) & (width_row<=interval[1]):\n",
    "                aux_classes.append(names_widths[i])\n",
    "    \n",
    "    df_added['width_wf_class'] = np.array(aux_classes)\n",
    "    return df_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58f984c7-178e-4d2e-8ced-55672df9857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### classification into 6 classes\n",
    "def aux_add_final_classes(df_sua,peak_borders=PEAK_BORDERS,final_classes=FINAL_CLASSES):\n",
    "    df_sua['final_class'] = 'NO_CLASS'\n",
    "    dict_cl_indices = {}\n",
    "    for cl in final_classes:\n",
    "        if cl=='DOWN_narrow_peak':\n",
    "            aux_df = df_sua[df_sua['wf_direction']=='DOWN']\n",
    "            aux_df = aux_df[aux_df['width_wf_class']=='narrow']\n",
    "            mask_peak = (aux_df['pref_phase_all_spikes']>=peak_borders[0]) & (aux_df['pref_phase_all_spikes']<=peak_borders[1])\n",
    "            aux_df = aux_df[mask_peak]\n",
    "            dict_cl_indices['DOWN_narrow_peak'] = aux_df.index\n",
    "        elif cl=='DOWN_narrow_other':\n",
    "            aux_df = df_sua[df_sua['wf_direction']=='DOWN']\n",
    "            aux_df = aux_df[aux_df['width_wf_class']=='narrow']\n",
    "            mask_peak = (aux_df['pref_phase_all_spikes']>=peak_borders[0]) & (aux_df['pref_phase_all_spikes']<=peak_borders[1])\n",
    "            aux_df = aux_df[~mask_peak]\n",
    "            dict_cl_indices['DOWN_narrow_other'] = aux_df.index\n",
    "        elif cl=='DOWN_medium':\n",
    "            aux_df = df_sua[df_sua['wf_direction']=='DOWN']\n",
    "            aux_df = aux_df[aux_df['width_wf_class']=='medium']\n",
    "            dict_cl_indices['DOWN_medium'] = aux_df.index\n",
    "        elif cl=='DOWN_wide':\n",
    "            aux_df = df_sua[df_sua['wf_direction']=='DOWN']\n",
    "            aux_df = aux_df[aux_df['width_wf_class']=='wide']\n",
    "            dict_cl_indices['DOWN_wide'] = aux_df.index\n",
    "        elif cl=='UP_peak':\n",
    "            aux_df = df_sua[df_sua['wf_direction']=='UP']\n",
    "            mask_peak = (aux_df['pref_phase_all_spikes']>=peak_borders[0]) & (aux_df['pref_phase_all_spikes']<=peak_borders[1])\n",
    "            aux_df = aux_df[mask_peak]\n",
    "            dict_cl_indices['UP_peak'] = aux_df.index\n",
    "        elif cl=='UP_other':\n",
    "            aux_df = df_sua[df_sua['wf_direction']=='UP']\n",
    "            mask_peak = (aux_df['pref_phase_all_spikes']>=peak_borders[0]) & (aux_df['pref_phase_all_spikes']<=peak_borders[1])\n",
    "            aux_df = aux_df[~mask_peak] \n",
    "            dict_cl_indices['UP_other'] = aux_df.index\n",
    "        else:\n",
    "            print('Undefined cell type.')\n",
    "    for cl in final_classes:\n",
    "        for i in dict_cl_indices[cl]:\n",
    "            df_sua.loc[i,'final_class'] = cl\n",
    "    return df_sua"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40464a2-4d6b-4581-bfbe-486280ec9881",
   "metadata": {},
   "source": [
    "## Dataframe calculation - the first part, computationaly expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e24b1c39-eaf7-41fe-b5b7-ae28e003bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for monkey in MONKEY_LIST:\n",
    "        print(monkey)\n",
    "        for date in params['dates'][monkey]['RS']:\n",
    "            print(date)\n",
    "            prop_list = []\n",
    "            for array in range(1,17): \n",
    "                print(array)\n",
    "                try:\n",
    "                    ### loading SUA spike trains and RB block\n",
    "                    try:\n",
    "                        spike_block = load_block(monkey,array,type_rec='RS',type_sig='spikes',date=date,data_folder=DATA_FOLDER) ### SUA\n",
    "                        RB_block = load_block(monkey,array,type_rec='RS',type_sig='RB',date=date,data_folder=DATA_FOLDER)\n",
    "                        num_cells = len(spike_block.segments[0].spiketrains)\n",
    "                        start_t_spikes_ms = int(np.floor(np.float64(spike_block.segments[0].spiketrains[0].t_start.magnitude)*1000))\n",
    "                        start_t_RB_ms = int(np.floor(np.float64(RB_block.segments[0].analogsignals[0].t_start.magnitude)*1000))\n",
    "                        print(f'Start t RB: {start_t_spikes_ms}')\n",
    "                        print(f'Start t spikes: {start_t_RB_ms}')\n",
    "                        if start_t_spikes_ms!=start_t_RB_ms:\n",
    "                            print('Spikes and ripples do not have the same start time.')\n",
    "                    except:\n",
    "                        print(f'Cannot read the spike file for date {date}, monkey {monkey}, array {array}.')\n",
    "                    try:\n",
    "                        df_OP = pd.read_csv(f'{DATA_FOLDER}/metadata/OP_maps_dataframes/{monkey}/OP_prop_OG_array{array}.csv')\n",
    "                    except:\n",
    "                        print(f'Cannot read OP maps for date {date}, monkey {monkey}, array {array}.')\n",
    "                    for cell in range(num_cells):\n",
    "                        spike_train = spike_block.segments[0].spiketrains[cell]\n",
    "                        cell_name = spike_train.annotations['nix_name']\n",
    "                        electrode_ID = spike_train.annotations['Electrode_ID']\n",
    "                        \n",
    "                        ### channel prop - additional info for a channel, such as OP, bad channel ID, array and area\n",
    "                        channel_prop = {}\n",
    "                        channel_prop['cell_name'] = cell_name\n",
    "                        ### OP\n",
    "                        try:\n",
    "                            ch_OP = df_OP[df_OP['Electrode_ID']==electrode_ID]\n",
    "                            if ch_OP['selectivity_01'].values[0]>0.2 and ch_OP['num_f0_high_jump'].values[0]<3:\n",
    "                                channel_prop['pref_OP'] = ch_OP['pref_OP'].values[0]\n",
    "                                channel_prop['selectivity_OP_01'] = ch_OP['selectivity_01'].values[0]\n",
    "                            else:\n",
    "                                channel_prop['pref_OP'] = np.nan\n",
    "                                channel_prop['selectivity_OP_01'] = ch_OP['selectivity_01'].values[0]\n",
    "                        except:\n",
    "                            channel_prop['pref_OP'] = np.nan\n",
    "                            channel_prop['selectivity_OP_01'] = np.nan\n",
    "                        ### channel order\n",
    "                        ch = aux_electrodeID_to_ch_order(monkey,date,electrode_ID,array,data_folder=DATA_FOLDER,type_rec='RS')\n",
    "                        channel_prop['channel_order'] = ch\n",
    "                        ### array\n",
    "                        channel_prop['array'] = array\n",
    "                        ### area\n",
    "                        if monkey in ['N','F']:\n",
    "                            name_area = 'Area'\n",
    "                        else:\n",
    "                            name_area = 'cortical_area'\n",
    "                        ch_area = spike_train.annotations[name_area]\n",
    "                        channel_prop['area'] = ch_area\n",
    "                        ### order in the spike train\n",
    "                        channel_prop['train_order'] = cell\n",
    "\n",
    "                        rb_phase_arr = sig_block_to_arr(RB_block,'RB_phase')\n",
    "                        rb_envelope_arr = sig_block_to_arr(RB_block,'RB_envelope_norm')\n",
    "                        rb_env_phase_arr = sig_block_to_arr(RB_block,'RB_envelope_phase')\n",
    "\n",
    "                        spike_arr = spike_block_to_arr(spike_block)\n",
    "\n",
    "                        ### cutting out common times only for N and F\n",
    "                        if monkey in ['N','F']:\n",
    "                            rb_phase_arr = cut_abs_times(rb_phase_arr,start_t_RB_ms,monkey,rec_type='RS',date=date,params=params)\n",
    "                            rb_envelope_arr = cut_abs_times(rb_envelope_arr,start_t_RB_ms,monkey,rec_type='RS',date=date,params=params)\n",
    "                            rb_env_phase_arr = cut_abs_times(rb_env_phase_arr,start_t_RB_ms,monkey,rec_type='RS',date=date,params=params)\n",
    "                            spike_arr = cut_abs_times(spike_arr,start_t_spikes_ms,monkey,rec_type='RS',date=date,params=params)\n",
    "                        \n",
    "                        rb_phase = rb_phase_arr[ch,:]\n",
    "                        rb_envelope = rb_envelope_arr[ch,:]\n",
    "                        rb_env_phase = rb_env_phase_arr[ch,:]\n",
    "                        spike_vector = spike_arr[cell,:]\n",
    "                        \n",
    "                        prop_dict = spike_train_prop_vec(spike_vector,rb_phase,rb_envelope,rb_env_phase,channel_prop=channel_prop) ### input already binned spikes\n",
    "                        prop_list.append(prop_dict)\n",
    "                except:\n",
    "                    print(f'For array {array}, the SUA properties were not calculated.')\n",
    "            df_prop = pd.DataFrame(prop_list)\n",
    "            ensure_dir_exists(f'{DF_FOLDER}/sua_prop/')\n",
    "            df_prop.to_pickle(f'{DF_FOLDER}/sua_prop/monkey{monkey}_all_arrays_date_{date}.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b07ec-b669-4d69-98d2-4273351af857",
   "metadata": {},
   "source": [
    "## Adding other properties and formating to the DF (computationaly easier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85bc19bf-8aa4-4f86-b038-79386c8e0439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n",
      "20170725\n",
      "20170809\n",
      "20170810\n",
      "N\n",
      "20240719_B1\n",
      "20240719_B2\n",
      "F\n",
      "20240122_B1\n",
      "20241216_B1\n",
      "A\n",
      "20190815\n",
      "20190816\n"
     ]
    }
   ],
   "source": [
    "for monkey in MONKEY_LIST: \n",
    "    print(monkey)\n",
    "    all_RS_dates = params['dates'][monkey]['RS']\n",
    "    for date in all_RS_dates:\n",
    "        print(date)\n",
    "        with open(f'{DF_FOLDER}/sua_prop/monkey{monkey}_all_arrays_date_{date}.pkl', \"rb\") as file:\n",
    "            df_sua = pickle.load(file)\n",
    "        df_added = aux_add_waveform_prop(df_sua)\n",
    "        df_added = aux_add_zscored_avg_waveform(df_added)\n",
    "        df_added = df_added[df_added['channel_order']>-1] ### erasing not working arrays\n",
    "        df_added = aux_add_width_classes(df_added,width_intervals=WIDTH_INTERVALS)\n",
    "        df_added = aux_add_up_down_classes(df_added)\n",
    "        df_added = aux_add_final_classes(df_added,peak_borders=PEAK_BORDERS,final_classes=FINAL_CLASSES)\n",
    "\n",
    "        #### saving new dataframes with properties as pickle\n",
    "        ensure_dir_exists(f'{DF_FOLDER}/sua_prop_all/')\n",
    "        df_added.to_pickle(f'{DF_FOLDER}/sua_prop_all/monkey{monkey}_all_arrays_date_{date}.pkl')\n",
    "        ### the copy warning is there only for the case of empty arrays, no worries about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fbccef0-8a2e-4b53-ab8b-9fff3f667dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              DOWN_wide\n",
       "1       DOWN_narrow_peak\n",
       "2      DOWN_narrow_other\n",
       "3              DOWN_wide\n",
       "4       DOWN_narrow_peak\n",
       "             ...        \n",
       "499          DOWN_medium\n",
       "500    DOWN_narrow_other\n",
       "501          DOWN_medium\n",
       "502          DOWN_medium\n",
       "503          DOWN_medium\n",
       "Name: final_class, Length: 504, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_added['final_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11415909-a1f1-4c68-a0d9-2d8607aa04c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FR', 'CV_ISI', 'ISI', 'env_th_median', 'list_phases', 'list_env',\n",
       "       'list_env_phases', 'list_phases_high_env', 'list_env_phases_high_env',\n",
       "       'list_phases_low_env', 'list_env_phases_low_env', 'FR_high_env_median',\n",
       "       'FR_low_env_median', 'FR_high_env_low_env_median_ratio',\n",
       "       'pref_phase_all_spikes', 'norm_phase_sel_01_all_spikes',\n",
       "       'pref_env_phase_all_spikes', 'norm_env_phase_sel_01_all_spikes',\n",
       "       'env_th_perc_10', 'env_th_perc_20', 'env_th_perc_30', 'env_th_perc_40',\n",
       "       'env_th_perc_50', 'env_th_perc_60', 'env_th_perc_70', 'env_th_perc_80',\n",
       "       'env_th_perc_90', 'env_th_perc_95', 'cell_name', 'pref_OP',\n",
       "       'selectivity_OP_01', 'channel_order', 'array', 'area', 'train_order',\n",
       "       'avg_wf', 'amp_wf', 'width_wf', 'avg_wf_zscored', 'amp_wf_zscored',\n",
       "       'width_wf_class', 'wf_direction', 'final_class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_added.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c367a55-3ba0-434e-9e46-5d049da841b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FR</th>\n",
       "      <th>CV_ISI</th>\n",
       "      <th>ISI</th>\n",
       "      <th>env_th_median</th>\n",
       "      <th>list_phases</th>\n",
       "      <th>list_env</th>\n",
       "      <th>list_env_phases</th>\n",
       "      <th>list_phases_high_env</th>\n",
       "      <th>list_env_phases_high_env</th>\n",
       "      <th>list_phases_low_env</th>\n",
       "      <th>...</th>\n",
       "      <th>area</th>\n",
       "      <th>train_order</th>\n",
       "      <th>avg_wf</th>\n",
       "      <th>amp_wf</th>\n",
       "      <th>width_wf</th>\n",
       "      <th>avg_wf_zscored</th>\n",
       "      <th>amp_wf_zscored</th>\n",
       "      <th>width_wf_class</th>\n",
       "      <th>wf_direction</th>\n",
       "      <th>final_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.107476</td>\n",
       "      <td>1.731616</td>\n",
       "      <td>[37, 29, 27, 33, 19, 13, 48, 34, 264, 6, 22, 1...</td>\n",
       "      <td>0.898995</td>\n",
       "      <td>[0.8949215, -1.6516726, 1.9185883, 0.4335102, ...</td>\n",
       "      <td>[3.580378, 0.61513877, 3.6505191, 3.8867853, 1...</td>\n",
       "      <td>[-0.3918044, -2.3370738, 0.32232544, 0.4845442...</td>\n",
       "      <td>[0.8949215, 1.9185883, 0.4335102, -2.2834458, ...</td>\n",
       "      <td>[-0.3918044, 0.32232544, 0.48454422, 1.9539795...</td>\n",
       "      <td>[-1.6516726, 2.6324809, -2.312513, 2.8026843, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>V1</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.07893936 uV, 0.009604962 uV, 0.104669385 u...</td>\n",
       "      <td>12.182018 uV</td>\n",
       "      <td>13</td>\n",
       "      <td>[-0.050143387, -0.014451916, 0.02386775, 0.065...</td>\n",
       "      <td>4.910469</td>\n",
       "      <td>wide</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN_wide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.566047</td>\n",
       "      <td>1.565210</td>\n",
       "      <td>[120, 27, 173, 44, 90, 40, 84, 20, 40, 86, 17,...</td>\n",
       "      <td>1.314136</td>\n",
       "      <td>[-0.52945757, -2.989535, 1.7835573, 2.7233076,...</td>\n",
       "      <td>[5.884698, 4.13634, 0.63234925, 1.6020149, 1.8...</td>\n",
       "      <td>[-0.46864057, 0.5003421, 2.345138, 1.2908846, ...</td>\n",
       "      <td>[-0.52945757, -2.989535, 2.7233076, -1.6106553...</td>\n",
       "      <td>[-0.46864057, 0.5003421, 1.2908846, -1.0384673...</td>\n",
       "      <td>[1.7835573, -1.2493649, 0.7245242, 2.5869122, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>V1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.044280175 uV, 0.04797673 uV, 0.054886095 uV...</td>\n",
       "      <td>5.9538403 uV</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.058323715, 0.06307975, 0.07196944, 0.077603...</td>\n",
       "      <td>7.660294</td>\n",
       "      <td>narrow</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN_narrow_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.527008</td>\n",
       "      <td>1.010187</td>\n",
       "      <td>[27, 1, 99, 43, 145, 118, 90, 33, 10, 57, 243,...</td>\n",
       "      <td>1.088546</td>\n",
       "      <td>[1.5148422, 2.7526646, 0.07995539, 0.6984406, ...</td>\n",
       "      <td>[3.41308, 3.7781377, 5.009789, 1.7155644, 1.41...</td>\n",
       "      <td>[-1.0516787, -0.9338419, 0.3463526, 1.1438483,...</td>\n",
       "      <td>[1.5148422, 2.7526646, 0.07995539, 0.6984406, ...</td>\n",
       "      <td>[-1.0516787, -0.9338419, 0.3463526, 1.1438483,...</td>\n",
       "      <td>[-0.18523695, -1.6737292, -0.3542702, 0.176791...</td>\n",
       "      <td>...</td>\n",
       "      <td>V1</td>\n",
       "      <td>2</td>\n",
       "      <td>[-0.00018575166 uV, 0.016559677 uV, 0.04155632...</td>\n",
       "      <td>5.0304017 uV</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.0076714493, 0.0167015, 0.05308408, 0.08355...</td>\n",
       "      <td>7.321743</td>\n",
       "      <td>narrow</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN_narrow_other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.880076</td>\n",
       "      <td>1.005134</td>\n",
       "      <td>[2, 60, 168, 115, 12, 301, 206, 50, 183, 22, 1...</td>\n",
       "      <td>1.088546</td>\n",
       "      <td>[1.2034215, -2.660083, -1.9840807, -0.50284547...</td>\n",
       "      <td>[2.0073838, 1.7620276, 0.60708755, 0.54813105,...</td>\n",
       "      <td>[-1.3341041, 0.9382869, 1.8672955, -3.1077988,...</td>\n",
       "      <td>[1.2034215, -2.660083, 2.875721, 0.20242125, 0...</td>\n",
       "      <td>[-1.3341041, 0.9382869, -1.4294983, -0.6522088...</td>\n",
       "      <td>[-1.9840807, -0.50284547, 2.3088422, -1.892213...</td>\n",
       "      <td>...</td>\n",
       "      <td>V1</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.13725783 uV, -0.14345522 uV, -0.1325626 uV...</td>\n",
       "      <td>4.0109205 uV</td>\n",
       "      <td>20</td>\n",
       "      <td>[-0.20722252, -0.2161767, -0.2004387, -0.15798...</td>\n",
       "      <td>5.795106</td>\n",
       "      <td>wide</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN_wide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.458824</td>\n",
       "      <td>1.158895</td>\n",
       "      <td>[9, 63, 9, 268, 151, 188, 202, 141, 103, 170, ...</td>\n",
       "      <td>1.041889</td>\n",
       "      <td>[-0.59491074, 0.16845854, 2.704239, 0.37656453...</td>\n",
       "      <td>[2.0509684, 1.8092152, 0.5843474, 1.5266342, 1...</td>\n",
       "      <td>[-1.17618, -1.2795454, -2.8362763, -1.4785236,...</td>\n",
       "      <td>[-0.59491074, 0.16845854, 0.37656453, -2.05416...</td>\n",
       "      <td>[-1.17618, -1.2795454, -1.4785236, -2.0827224,...</td>\n",
       "      <td>[2.704239, 3.1325738, -0.1967004, -1.6087348, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>V1</td>\n",
       "      <td>4</td>\n",
       "      <td>[0.025834981 uV, 0.027140008 uV, 0.025227027 u...</td>\n",
       "      <td>5.086688 uV</td>\n",
       "      <td>5</td>\n",
       "      <td>[0.031549763, 0.033435132, 0.030671455, 0.0297...</td>\n",
       "      <td>7.348716</td>\n",
       "      <td>narrow</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>DOWN_narrow_peak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FR    CV_ISI                                                ISI  \\\n",
       "0  7.107476  1.731616  [37, 29, 27, 33, 19, 13, 48, 34, 264, 6, 22, 1...   \n",
       "1  7.566047  1.565210  [120, 27, 173, 44, 90, 40, 84, 20, 40, 86, 17,...   \n",
       "2  4.527008  1.010187  [27, 1, 99, 43, 145, 118, 90, 33, 10, 57, 243,...   \n",
       "3  7.880076  1.005134  [2, 60, 168, 115, 12, 301, 206, 50, 183, 22, 1...   \n",
       "4  5.458824  1.158895  [9, 63, 9, 268, 151, 188, 202, 141, 103, 170, ...   \n",
       "\n",
       "   env_th_median                                        list_phases  \\\n",
       "0       0.898995  [0.8949215, -1.6516726, 1.9185883, 0.4335102, ...   \n",
       "1       1.314136  [-0.52945757, -2.989535, 1.7835573, 2.7233076,...   \n",
       "2       1.088546  [1.5148422, 2.7526646, 0.07995539, 0.6984406, ...   \n",
       "3       1.088546  [1.2034215, -2.660083, -1.9840807, -0.50284547...   \n",
       "4       1.041889  [-0.59491074, 0.16845854, 2.704239, 0.37656453...   \n",
       "\n",
       "                                            list_env  \\\n",
       "0  [3.580378, 0.61513877, 3.6505191, 3.8867853, 1...   \n",
       "1  [5.884698, 4.13634, 0.63234925, 1.6020149, 1.8...   \n",
       "2  [3.41308, 3.7781377, 5.009789, 1.7155644, 1.41...   \n",
       "3  [2.0073838, 1.7620276, 0.60708755, 0.54813105,...   \n",
       "4  [2.0509684, 1.8092152, 0.5843474, 1.5266342, 1...   \n",
       "\n",
       "                                     list_env_phases  \\\n",
       "0  [-0.3918044, -2.3370738, 0.32232544, 0.4845442...   \n",
       "1  [-0.46864057, 0.5003421, 2.345138, 1.2908846, ...   \n",
       "2  [-1.0516787, -0.9338419, 0.3463526, 1.1438483,...   \n",
       "3  [-1.3341041, 0.9382869, 1.8672955, -3.1077988,...   \n",
       "4  [-1.17618, -1.2795454, -2.8362763, -1.4785236,...   \n",
       "\n",
       "                                list_phases_high_env  \\\n",
       "0  [0.8949215, 1.9185883, 0.4335102, -2.2834458, ...   \n",
       "1  [-0.52945757, -2.989535, 2.7233076, -1.6106553...   \n",
       "2  [1.5148422, 2.7526646, 0.07995539, 0.6984406, ...   \n",
       "3  [1.2034215, -2.660083, 2.875721, 0.20242125, 0...   \n",
       "4  [-0.59491074, 0.16845854, 0.37656453, -2.05416...   \n",
       "\n",
       "                            list_env_phases_high_env  \\\n",
       "0  [-0.3918044, 0.32232544, 0.48454422, 1.9539795...   \n",
       "1  [-0.46864057, 0.5003421, 1.2908846, -1.0384673...   \n",
       "2  [-1.0516787, -0.9338419, 0.3463526, 1.1438483,...   \n",
       "3  [-1.3341041, 0.9382869, -1.4294983, -0.6522088...   \n",
       "4  [-1.17618, -1.2795454, -1.4785236, -2.0827224,...   \n",
       "\n",
       "                                 list_phases_low_env  ... area  train_order  \\\n",
       "0  [-1.6516726, 2.6324809, -2.312513, 2.8026843, ...  ...   V1            0   \n",
       "1  [1.7835573, -1.2493649, 0.7245242, 2.5869122, ...  ...   V1            1   \n",
       "2  [-0.18523695, -1.6737292, -0.3542702, 0.176791...  ...   V1            2   \n",
       "3  [-1.9840807, -0.50284547, 2.3088422, -1.892213...  ...   V1            3   \n",
       "4  [2.704239, 3.1325738, -0.1967004, -1.6087348, ...  ...   V1            4   \n",
       "\n",
       "                                              avg_wf        amp_wf  width_wf  \\\n",
       "0  [-0.07893936 uV, 0.009604962 uV, 0.104669385 u...  12.182018 uV        13   \n",
       "1  [0.044280175 uV, 0.04797673 uV, 0.054886095 uV...  5.9538403 uV         4   \n",
       "2  [-0.00018575166 uV, 0.016559677 uV, 0.04155632...  5.0304017 uV         5   \n",
       "3  [-0.13725783 uV, -0.14345522 uV, -0.1325626 uV...  4.0109205 uV        20   \n",
       "4  [0.025834981 uV, 0.027140008 uV, 0.025227027 u...   5.086688 uV         5   \n",
       "\n",
       "                                      avg_wf_zscored  amp_wf_zscored  \\\n",
       "0  [-0.050143387, -0.014451916, 0.02386775, 0.065...        4.910469   \n",
       "1  [0.058323715, 0.06307975, 0.07196944, 0.077603...        7.660294   \n",
       "2  [-0.0076714493, 0.0167015, 0.05308408, 0.08355...        7.321743   \n",
       "3  [-0.20722252, -0.2161767, -0.2004387, -0.15798...        5.795106   \n",
       "4  [0.031549763, 0.033435132, 0.030671455, 0.0297...        7.348716   \n",
       "\n",
       "   width_wf_class  wf_direction        final_class  \n",
       "0            wide          DOWN          DOWN_wide  \n",
       "1          narrow          DOWN   DOWN_narrow_peak  \n",
       "2          narrow          DOWN  DOWN_narrow_other  \n",
       "3            wide          DOWN          DOWN_wide  \n",
       "4          narrow          DOWN   DOWN_narrow_peak  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_added.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04067af-3516-438c-aeb5-08bae4a1b3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa27e11-ef4b-4bf9-aff3-c1ad9ea131be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
